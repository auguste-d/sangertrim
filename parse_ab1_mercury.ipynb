{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d1c040-f990-4a62-bc12-c7a7d28d357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mercury as mr\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1041d617-95d0-4736-937e-4773e77e7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818eadd1-7323-49e1-ab78-e8149ab3aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Checkbox\",\n    \"value\": false,\n    \"label\": \"Show code\",\n    \"model_id\": \"9c3cfae564cd40bdab28abcb83c9364a\",\n    \"code_uid\": \"Checkbox.0.50.70.1-rand11fb0f66\",\n    \"url_key\": \"\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3cfae564cd40bdab28abcb83c9364a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Checkbox"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_code = mr.Checkbox(value=False, label=\"Show code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db21f3b4-4bf1-435e-81df-b276a1179902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"App\",\n    \"title\": \"16s Sequencing Data Analysis\",\n    \"description\": \"Use to trim Sanger sequencing, merge fwd and reverse reads\",\n    \"show_code\": false,\n    \"show_prompt\": false,\n    \"output\": \"app\",\n    \"schedule\": \"\",\n    \"notify\": \"{}\",\n    \"continuous_update\": true,\n    \"static_notebook\": false,\n    \"show_sidebar\": true,\n    \"full_screen\": true,\n    \"allow_download\": true,\n    \"allow_share\": true,\n    \"stop_on_error\": false,\n    \"model_id\": \"mercury-app\",\n    \"code_uid\": \"App.0.50.110.1-rand551a7ca6\"\n}",
      "text/html": [
       "<h3>Mercury Application</h3><small>This output won't appear in the web app.</small>"
      ],
      "text/plain": [
       "mercury.App"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = mr.App(title=\"16s Sequencing Data Analysis\", description = \"Use to trim Sanger sequencing, merge fwd and reverse reads\", \\\n",
    "             show_code = show_code.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d998f38e-ab9d-4452-bab1-6c98b3fb6410",
   "metadata": {},
   "source": [
    "## Forward read plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bad67b2-436c-4693-81c8-00da0b2b5eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"File\",\n    \"max_file_size\": \"10MB\",\n    \"label\": \"Upload forward read\",\n    \"model_id\": \"1b2d49eeb2004e79bf44a0c8e6e66497\",\n    \"code_uid\": \"File.0.50.74.1-randcf0632fa\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2d49eeb2004e79bf44a0c8e6e66497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.File"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file1 = mr.File(label = 'Upload forward read', max_file_size = '10MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6acc6b57-67c9-493e-aad5-d9eceffdcc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file name: None\n",
      "Uploaded file path: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uploaded file name: {file1.filename}\")\n",
    "print(f\"Uploaded file path: {file1.filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01218b97-13e0-4430-bfea-810904af3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trimmed_fasta_with_ambiguities(output_title, base_calls, ambiguous_dict, \\\n",
    "                                            trim_start, trim_end, orient = 'F'):\n",
    "    \"\"\"\n",
    "    Generates a FASTA file with only the trimmed sequence and ambiguous base calls.\n",
    "\n",
    "    Args:\n",
    "        output_title (str): Title for the FASTA file.\n",
    "        base_calls (str): Original base calls as a string.\n",
    "        ambiguous_dict (dict): Dictionary mapping positions (0-based) to IUPAC codes.\n",
    "        trim_start (int): Start position for trimming (0-based).\n",
    "        trim_end (int): End position for trimming (0-based).\n",
    "    \n",
    "    Returns:\n",
    "        None. Outputs a trimmed FASTA file.\n",
    "    \"\"\"\n",
    "    # Convert the base_calls string into a list for easy modification\n",
    "    sequence_with_ambiguities = list(base_calls)\n",
    "\n",
    "    # Replace bases at ambiguous positions with the corresponding IUPAC code\n",
    "    for pos, iupac_code in ambiguous_dict.items():\n",
    "        if trim_start <= pos < trim_end:  # Only modify positions within the trimmed range\n",
    "            sequence_with_ambiguities[pos] = iupac_code\n",
    "\n",
    "    # Slice the sequence to include only the trimmed portion\n",
    "    trimmed_sequence_with_ambiguities = ''.join(sequence_with_ambiguities[trim_start:trim_end])\n",
    "    sequence = Seq(trimmed_sequence_with_ambiguities)\n",
    "\n",
    "    # Create a SeqRecord object for writing to FASTA\n",
    "    seq_record = SeqRecord(sequence, id=output_title, description=\"Trimmed sequence with ambiguous base calls\")\n",
    "\n",
    "    # Write the trimmed sequence to a FASTA file\n",
    "    # fasta_file = f\"{output_title}_trimmed.fasta\"\n",
    "    \n",
    "    # with open(fasta_file, \"w\") as output_handle:\n",
    "    \n",
    "        #if orient == 'R':\n",
    "            #SeqIO.write(seq_record.reverse_complement(), output_handle, \"fasta\")\n",
    "        \n",
    "        #else:\n",
    "            #SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "\n",
    "    # print(f\"Trimmed FASTA file '{fasta_file}' has been generated.\")\n",
    "    \n",
    "    return seq_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf50e0a4-ac13-4a59-be7d-67359dc05204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate ambiguous calls to IUPAC code\n",
    "def translate_to_iupac(ambiguous_bases):\n",
    "    # Sort the ambiguous bases to ensure they match the dictionary keys\n",
    "    sorted_bases = ''.join(sorted(ambiguous_bases))\n",
    "    return base_to_iupac.get(sorted_bases, 'N')  # Return 'N' if no match is found\n",
    "\n",
    "# Parameters\n",
    "quality_threshold = 40     # Quality score threshold for trimming\n",
    "min_consecutive_bases = 5  # Minimum number of consecutive high-quality bases needed to determine trim point\n",
    "\n",
    "# Function to find the first and last position to keep based on quality threshold\n",
    "def find_trim_position(phred_scores, direction='start'):\n",
    "    if direction == 'start':\n",
    "        for i in range(len(phred_scores) - min_consecutive_bases + 1):\n",
    "            if all(score >= quality_threshold for score in phred_scores[i:i + min_consecutive_bases]):\n",
    "                return i\n",
    "    elif direction == 'end':\n",
    "        for i in range(len(phred_scores) - min_consecutive_bases, -1, -1):\n",
    "            if all(score >= quality_threshold for score in phred_scores[i:i + min_consecutive_bases]):\n",
    "                return i + min_consecutive_bases\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0cb8cdd-e228-4c2c-bcff-888c29c7f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IUPAC nucleotide code dictionary\n",
    "iupac_codes = {\n",
    "    \"A\": \"A\",\n",
    "    \"C\": \"C\",\n",
    "    \"G\": \"G\",\n",
    "    \"T\": \"T\",\n",
    "    \"R\": \"AG\",    # A or G\n",
    "    \"Y\": \"CT\",    # C or T\n",
    "    \"S\": \"GC\",    # G or C\n",
    "    \"W\": \"AT\",    # A or T\n",
    "    \"K\": \"GT\",    # G or T\n",
    "    \"M\": \"AC\",    # A or C\n",
    "    \"B\": \"CGT\",   # C or G or T\n",
    "    \"D\": \"AGT\",   # A or G or T\n",
    "    \"H\": \"ACT\",   # A or C or T\n",
    "    \"V\": \"ACG\",   # A or C or G\n",
    "    \"N\": \"ACGT\"   # any base\n",
    "}\n",
    "\n",
    "# Reverse mapping from bases to IUPAC code\n",
    "base_to_iupac = {''.join(sorted(v)): k for k, v in iupac_codes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee609e9-da42-4416-9725-ad0b29101f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq1_title = mr.Text(value='sequence', label='Name this sequence', rows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c869177-29d1-4232-bbbf-91ff8b928395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ambig_calls_and_plot(record, orient = 'F', output_title = 'sequence'):\n",
    "\n",
    "    # Extract peak locations, base calls, and quality scores\n",
    "    peak_locations = record.annotations['abif_raw']['PLOC2']\n",
    "    base_calls = record.annotations['abif_raw']['PBAS2'].decode('ascii')\n",
    "    phred_scores = record.letter_annotations[\"phred_quality\"]\n",
    "\n",
    "    # Find high-quality trimming positions\n",
    "    trim_start = find_trim_position(phred_scores, 'start')\n",
    "    trim_end = find_trim_position(phred_scores, 'end')\n",
    "    trimmed_len = trim_end - trim_start\n",
    "\n",
    "    # Define ambiguity threshold and the number of bases per plot\n",
    "    ambiguity_threshold = 3  # e.g., highest peak must be 3 times greater than the next highest\n",
    "    bases_per_plot = 50\n",
    "\n",
    "    # Extract trace data for G, A, T, C\n",
    "    channels = ['DATA9', 'DATA10', 'DATA11', 'DATA12']\n",
    "    trace_data = {base: record.annotations['abif_raw'][channel] for base, channel in zip(\"GATC\", channels)}\n",
    "\n",
    "    # Find global max intensity and max Phred score for consistent plotting\n",
    "    max_intensity = max(max(trace_data[base]) for base in \"GATC\")\n",
    "    max_phred_score = max(phred_scores)\n",
    "\n",
    "    # Set consistent y-limits\n",
    "    intensity_ylim = (-0.4, max_intensity * 1.1)  # a little above max to give space\n",
    "    phred_ylim = (0, max_phred_score + 5)  # add a small buffer above max Phred\n",
    "\n",
    "    # Initialize lists for ambiguous positions, original base calls, and alternatives\n",
    "    ambiguous_positions = []\n",
    "    original_base_calls = []\n",
    "    alternative_base_calls = []\n",
    "    alternative_intensities = []\n",
    "\n",
    "    # Loop through all positions in the sequence to check for ambiguity\n",
    "    for i, position in enumerate(peak_locations):\n",
    "        intensities = {base: trace_data[base][position] for base in \"GATC\"}\n",
    "        sorted_bases = sorted(intensities, key=intensities.get, reverse=True)\n",
    "\n",
    "        # Check for ambiguous base calls based on the threshold\n",
    "        if intensities[sorted_bases[0]] < ambiguity_threshold * intensities[sorted_bases[1]]:\n",
    "            ambiguous_positions.append(i)\n",
    "            original_base_calls.append(base_calls[i])\n",
    "            alternatives = [(base, intensities[base]) for base in sorted_bases if intensities[base] >= intensities[sorted_bases[0]] / ambiguity_threshold]\n",
    "            alternative_base_calls.append([base for base, _ in alternatives])\n",
    "            alternative_intensities.append([intensity for _, intensity in alternatives])\n",
    "\n",
    "    # Make a dictionary with the position of the ambiguous calls and the corresponding IUPAC code\n",
    "    ambiguous_dict = {}\n",
    "    for position, alternatives in zip(ambiguous_positions, alternative_base_calls):\n",
    "        ambiguous_dict[position] = translate_to_iupac(alternatives)\n",
    "\n",
    "    # Loop through the sequence in chunks of `bases_per_plot` and plot each chunk\n",
    "    # num_chunks = len(base_calls) // bases_per_plot + (1 if len(base_calls) % bases_per_plot else 0)\n",
    "\n",
    "    # Output the start and end positions for trimming (adjusted for display purposes)\n",
    "    print(\"Trim Start Position:\", trim_start + 1)  # Adjust display only (shifted by 1)\n",
    "    print(\"Trim End Position:\", trim_end)  # No need to adjust since this is end-exclusive\n",
    "\n",
    "    # Set initial values for start and end based on the number of bases per plot\n",
    "    # Set initial values for start and end based on the number of bases per plot\n",
    "    start = 0\n",
    "    end = min(len(base_calls), bases_per_plot)  # Show first 50 bases initially\n",
    "    \n",
    "    # Plot the trace data for the initial chunk\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    colors = {'A': 'green', 'C': 'blue', 'G': 'black', 'T': 'red'}\n",
    "    slider_color = 'White'\n",
    "    \n",
    "    # Create a secondary y-axis for Phred scores\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # App slider widget\n",
    "    pos_to_plot = mr.Slider(value=0, min=0, max=len(base_calls), label=\"Region to view\", \n",
    "                        step=1, url_key=\"slider\")\n",
    "    \n",
    "    # Function to plot the current chunk of data\n",
    "    def plot_chunk(start, end):\n",
    "        ax1.clear()  # Clear previous data\n",
    "        ax2.clear()  # Clear Phred score data\n",
    "\n",
    "        for i, position in enumerate(peak_locations[start:end]):\n",
    "            for base in \"GACT\":\n",
    "                ax1.plot(start + i + 1, trace_data[base][position], 'o', color=colors[base], label=base if start + i == 0 else \"\")\n",
    "        \n",
    "        # Annotate original base calls below the x-axis\n",
    "        for i, (pos, base_call) in enumerate(zip(range(start + 1, end + 1), base_calls[start:end])):\n",
    "            ax1.text(pos, -0.15, base_call, ha='center', va='top', transform=ax1.get_xaxis_transform(), fontsize=8)\n",
    "    \n",
    "        # Annotate ambiguous calls\n",
    "        for pos in range(start, end):\n",
    "            if pos in ambiguous_dict:\n",
    "                ax1.text(pos + 1, -0.25, ambiguous_dict[pos], ha='center', va='top', transform=ax1.get_xaxis_transform(), fontsize=8, color='darkorange')\n",
    "    \n",
    "        # Set plot limits and labels\n",
    "        ax1.set_xlim(start + 1, end)\n",
    "        ax1.set_ylim(intensity_ylim)\n",
    "        ax1.set_xlabel('Base Number')\n",
    "        ax1.set_ylabel('Signal Intensity')\n",
    "        ax1.set_title(f'Sanger Sequencing Chromatogram (Bases {start + 1} to {end})')\n",
    "    \n",
    "        # Update the Phred score axis\n",
    "        ax2.plot(range(start + 1, end + 1), phred_scores[start:end], 's-', color='purple', label='Phred Quality Score', alpha=0.7)\n",
    "        ax2.set_ylabel('Phred Quality Score')\n",
    "        ax2.yaxis.set_label_position(\"right\")\n",
    "        ax2.yaxis.tick_right()\n",
    "        ax2.set_ylim(phred_ylim)\n",
    "        ax2.legend(loc=\"upper right\")\n",
    "        ax1.legend(loc=\"upper left\")\n",
    "        plt.draw()\n",
    "\n",
    "    # Initial plot of the first chunk\n",
    "    plot_chunk(pos_to_plot.value, pos_to_plot.value + 75)\n",
    "    \n",
    "    # Slider params\n",
    "    #axis_position = plt.axes([0.2, 0.1, 0.65, 0.03], facecolor=slider_color)\n",
    "    #slider_position = Slider(axis_position, 'Pos', 0, max(0, len(base_calls) - bases_per_plot))\n",
    "    \n",
    "    # Update function for the slider\n",
    "    #def update(val):\n",
    "        #pos = int(slider_position.val)\n",
    "        #start = pos\n",
    "        #end = min(start + bases_per_plot, len(base_calls))\n",
    "        #plot_chunk(start, end)\n",
    "    \n",
    "    # Connect the slider to the update function\n",
    "    #slider_position.on_changed(update)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Convert the base_calls string into a list for easy modification\n",
    "    sequence_with_ambiguities = list(base_calls)\n",
    "\n",
    "    # Replace bases at ambiguous positions with the corresponding IUPAC code\n",
    "    for pos, iupac_code in ambiguous_dict.items():\n",
    "        sequence_with_ambiguities[pos] = iupac_code\n",
    "\n",
    "    # Slice the sequence to include only the trimmed portion\n",
    "    trimmed_sequence_with_ambiguities = ''.join(sequence_with_ambiguities[trim_start:trim_end])\n",
    "    sequence = Seq(trimmed_sequence_with_ambiguities)\n",
    "\n",
    "    # Create a SeqRecord object for writing to FASTA\n",
    "    seq_record = SeqRecord(sequence, id=output_title, description=\"Trimmed sequence with ambiguous base calls\")\n",
    "\n",
    "    # Write the trimmed sequence to a FASTA file\n",
    "    # fasta_file = f\"{output_title}_trimmed.fasta\"\n",
    "    \n",
    "    # with open(fasta_file, \"w\") as output_handle:\n",
    "    \n",
    "        #if orient == 'R':\n",
    "            #SeqIO.write(seq_record.reverse_complement(), output_handle, \"fasta\")\n",
    "        \n",
    "        #else:\n",
    "            #SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "\n",
    "    # print(f\"Trimmed FASTA file '{fasta_file}' has been generated.\")\n",
    "\n",
    "    # Assuming `base_calls` is the original base calls string, `ambiguous_dict` contains ambiguous positions,\n",
    "    # and `trim_start` and `trim_end` are the start and end positions for trimming.\n",
    "    \n",
    "    # seq_record = generate_trimmed_fasta_with_ambiguities(output_title, base_calls, ambiguous_dict, trim_start, trim_end, orient=orient)\n",
    "    # Include the Phred scores with the seq record\n",
    "    seq_record.letter_annotations[\"phred_score\"] = phred_scores[trim_start:trim_end]\n",
    "\n",
    "    # Handle reverse complement if needed\n",
    "    if orient == 'R':\n",
    "        phred_scores.reverse()\n",
    "        return seq_record.reverse_complement()\n",
    "    else:\n",
    "        return seq_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf4f88-e6b9-434d-9141-211ee0e93a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aecbc0ac-39a2-440c-87d7-270a39992bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate1 = mr.Button(label = \"Generate fwd plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0b03fd-e1b5-40a6-9659-adbe6699fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if generate1.clicked:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f5e8027-c489-415b-89f0-7c798ab28218",
   "metadata": {},
   "outputs": [],
   "source": [
    "record1 = None\n",
    "if file1.filepath is not None:\n",
    "    with open(file1.filepath, \"rb\") as infile:\n",
    "        record1 = SeqIO.read(infile, \"abi\")\n",
    "    seq1 = make_ambig_calls_and_plot(record1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01cd42-68f2-43b3-9618-c9597d4c5e93",
   "metadata": {},
   "source": [
    "## Reverse read plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7440e0a0-dd61-4d38-ba06-15a954ab8910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"File\",\n    \"max_file_size\": \"10MB\",\n    \"label\": \"Upload reverse read\",\n    \"model_id\": \"360383bb07644c51abfd8ccfd01fd67c\",\n    \"code_uid\": \"File.0.50.74.1-randea61bf91\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360383bb07644c51abfd8ccfd01fd67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.File"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file2 = mr.File(label = 'Upload reverse read', max_file_size = '10MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68157ce-27da-427c-9010-33972da18c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file name: None\n",
      "Uploaded file path: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uploaded file name: {file2.filename}\")\n",
    "print(f\"Uploaded file path: {file2.filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8515dc73-176f-4fae-93a4-1c262b069aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate2 = mr.Button(label = \"Generate fwd plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c594fd9-876e-4996-820f-edc79eba9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq2_title = mr.Text(value='sequence', label='Name this sequence', rows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af6fdaa-35f2-49e2-9c0d-d24fe82a2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if generate2.clicked:\n",
    "record2 = None\n",
    "if file2.filepath is not None:\n",
    "    with open(file2.filepath, \"rb\") as infile:\n",
    "        record2 = SeqIO.read(infile, \"abi\")\n",
    "\n",
    "    seq2 = make_ambig_calls_and_plot(record2, orient = 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ee340cb-65cf-4a63-9d2e-3ff8a03199ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dutcheah/Projects/mercury/.venv/lib/python3.8/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "\n",
    "# Perform local alignment using Smith-Waterman\n",
    "def align_sequences(seq1, seq2):\n",
    "    # Perform local alignment using Smith-Waterman (localms)\n",
    "    alignments = pairwise2.align.localms(seq1, seq2, 2, -1, -5, -2, one_alignment_only=True)\n",
    "    \n",
    "    # Return the best alignment\n",
    "    return alignments[0]\n",
    "\n",
    "# Function to generate consensus sequence based on Phred scores\n",
    "def generate_consensus_with_phred(aligned_seq1, aligned_seq2, phred_scores1, phred_scores2):\n",
    "    consensus = []\n",
    "\n",
    "    # Iterate through the aligned sequences and compare each base\n",
    "    for i, (base1, base2) in enumerate(zip(aligned_seq1, aligned_seq2)):\n",
    "        # Handle gaps\n",
    "        if base1 == '-':\n",
    "            consensus.append(base2)\n",
    "        elif base2 == '-':\n",
    "            consensus.append(base1)\n",
    "        elif base1 == base2:\n",
    "            consensus.append(base1)  # If bases are the same, use either one\n",
    "        else:\n",
    "            # Compare Phred scores to choose the base with the higher score\n",
    "            if phred_scores1[i] > phred_scores2[i]:\n",
    "                consensus.append(base1)\n",
    "            elif phred_scores2[i] > phred_scores1[i]:\n",
    "                consensus.append(base2)\n",
    "            # this would be unlikely, but would handle situations where phred scores are equal\n",
    "            elif phred_scores1[i] == phred_scores2[i]:\n",
    "                # first will need to convert any IUPAC codes *back* to bases:\n",
    "                possible_calls = set()\n",
    "                if base1 not in ['A', 'C', 'G', 'T']:\n",
    "                    base1_set = set(iupac_codes[base1])\n",
    "                    possible_calls.update(base1_set)\n",
    "                    \n",
    "                else: possible_calls.add(base1)\n",
    "                        \n",
    "                if base2 not in ['A', 'C', 'G', 'T']:\n",
    "                    base2_set = set(iupac_codes[base2])\n",
    "                    possible_calls.update(base2_set)\n",
    "                    \n",
    "                else: possible_calls.add(base2)\n",
    "                \n",
    "                sorted_possible_calls = ''.join(sorted(list(possible_calls)))\n",
    "                consensus.append(base_to_iupac.get(sorted_possible_calls, 'N'))  # Return 'N' if no match is found\n",
    "                \n",
    "    return ''.join(consensus)\n",
    "\n",
    "# Main function to align sequences and generate the consensus\n",
    "def align_and_generate_consensus(seq1, seq2):\n",
    "    # Align sequences\n",
    "    best_alignment = align_sequences(seq1.seq, seq2.seq)\n",
    "    \n",
    "    phred_scores1 = seq1.letter_annotations[\"phred_score\"]\n",
    "    phred_scores2 = seq2.letter_annotations[\"phred_score\"]\n",
    "    \n",
    "    # Extract the aligned sequences\n",
    "    aligned_seq1, aligned_seq2, score, start, end = best_alignment\n",
    "    \n",
    "    # Generate consensus sequence based on Phred scores\n",
    "    consensus_sequence = generate_consensus_with_phred(aligned_seq1, aligned_seq2, phred_scores1, phred_scores2)\n",
    "\n",
    "    # Print the alignment and the consensus sequence\n",
    "    print(\"Alignment:\")\n",
    "    print(pairwise2.format_alignment(*best_alignment))\n",
    "\n",
    "    # Print the alignment and the consensus sequence\n",
    "    print(f\"Consensus sequence generated with length of {str(len(consensus_sequence))} bases.\")\n",
    "    \n",
    "    return consensus_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2340b-36fe-4fe5-b1d9-3331532d877f",
   "metadata": {},
   "source": [
    "## Find overlap between forward and reverse reads and merge sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a59887e6-a1d9-4034-ad70-a10f4a4649ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Button\",\n    \"label\": \"Find overlap consensus\",\n    \"style\": \"primary\",\n    \"value\": false,\n    \"model_id\": \"52d5fc10c10a41e0bf1226763b1850c9\",\n    \"code_uid\": \"Button.0.50.58.1-randd9c50f28\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d5fc10c10a41e0bf1226763b1850c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Button"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate3 = mr.Button(label = \"Find overlap consensus\")\n",
    "\n",
    "if generate3.clicked:\n",
    "    consensus = align_and_generate_consensus(seq1, seq2)\n",
    "    print(consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42ed3fe0-52e5-415a-a132-b63a9ad900a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Text\",\n    \"value\": \"\",\n    \"sanitize\": true,\n    \"rows\": 1,\n    \"label\": \"Name the merged sequence for export\",\n    \"model_id\": \"faa1e623e2e04d5b85f758b73f1c3761\",\n    \"code_uid\": \"Text.0.50.78.1-randb8583ef5\",\n    \"url_key\": \"\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa1e623e2e04d5b85f758b73f1c3761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Text\",\n    \"value\": \"\",\n    \"sanitize\": true,\n    \"rows\": 1,\n    \"label\": \"Give a description of the file\",\n    \"model_id\": \"38777bf6baa24b84ae381282633709e5\",\n    \"code_uid\": \"Text.0.50.78.2-rand7f819aa6\",\n    \"url_key\": \"\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38777bf6baa24b84ae381282633709e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Button\",\n    \"label\": \"Write to FASTA\",\n    \"style\": \"primary\",\n    \"value\": false,\n    \"model_id\": \"7e6df96e098c49179c624c372b1f1715\",\n    \"code_uid\": \"Button.0.50.58.4-rand4eb0e88c\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6df96e098c49179c624c372b1f1715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Button"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_title = mr.Text(value='', label='Name the merged sequence for export', rows = 1)\n",
    "merge_desc = mr.Text(value='', label='Give a description of the file', rows = 1)\n",
    "\n",
    "generate4 = mr.Button(label = \"Write to FASTA\")\n",
    "\n",
    "if generate4.clicked:\n",
    "    with open(f\"/home/dutcheah/Projects/mercury/merged_fastas/{merge_title.value}.fasta\", 'w') as outfile:\n",
    "        SeqIO.write(SeqRecord(Seq(consensus), id=merge_title.value, description=merge_desc.value), outfile, 'fasta')\n",
    "\n",
    "    print(\"Fasta successfully generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ea2e1-332b-4be4-90bb-4e5451e164db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
