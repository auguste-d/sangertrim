{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68d1c040-f990-4a62-bc12-c7a7d28d357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mercury as mr\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3380ba3-226e-424e-8110-dd33c86fa31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1041d617-95d0-4736-937e-4773e77e7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0bd228-2c5b-4973-a864-68841c6a1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string, color = None):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad16fff6-5957-44b4-9f67-e93483ea8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(string, color = None):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    return colorstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c78989-875a-4348-9482-fbfc801d4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an easy way for ambiguous nucleotides to be easily identified\n",
    "def format_nucleotides(nucleotide_string):\n",
    "    formatted_string = \"\"\n",
    "    for char in nucleotide_string:\n",
    "        if char in \"ATCG\":\n",
    "            formatted_string += char\n",
    "        else:\n",
    "            formatted_string += \"<span style='background: gray; color:red; font-weight:bold, font-size: 250%'>{}</span>\".format(char)\n",
    "    printmd(formatted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818eadd1-7323-49e1-ab78-e8149ab3aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Checkbox\",\n    \"value\": false,\n    \"label\": \"Show code\",\n    \"model_id\": \"3f0ba8e4bf7d43c583dc35ec4ff9fb8c\",\n    \"code_uid\": \"Checkbox.0.50.70.1-rand9348593c\",\n    \"url_key\": \"\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0ba8e4bf7d43c583dc35ec4ff9fb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Checkbox"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_code = mr.Checkbox(value=False, label=\"Show code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db21f3b4-4bf1-435e-81df-b276a1179902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"App\",\n    \"title\": \"16s Sequencing Data Analysis\",\n    \"description\": \"Use to trim Sanger sequencing, merge fwd and reverse reads\",\n    \"show_code\": false,\n    \"show_prompt\": false,\n    \"output\": \"app\",\n    \"schedule\": \"\",\n    \"notify\": \"{}\",\n    \"continuous_update\": true,\n    \"static_notebook\": false,\n    \"show_sidebar\": true,\n    \"full_screen\": true,\n    \"allow_download\": true,\n    \"allow_share\": true,\n    \"stop_on_error\": false,\n    \"model_id\": \"mercury-app\",\n    \"code_uid\": \"App.0.50.110.1-rand5b5fb7f8\"\n}",
      "text/html": [
       "<h3>Mercury Application</h3><small>This output won't appear in the web app.</small>"
      ],
      "text/plain": [
       "mercury.App"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = mr.App(title=\"16s Sequencing Data Analysis\", description = \"Use to trim Sanger sequencing, merge fwd and reverse reads\", \\\n",
    "             show_code = show_code.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d998f38e-ab9d-4452-bab1-6c98b3fb6410",
   "metadata": {},
   "source": [
    "## Forward read plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bad67b2-436c-4693-81c8-00da0b2b5eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"File\",\n    \"max_file_size\": \"10MB\",\n    \"label\": \"Upload forward read\",\n    \"model_id\": \"d8cf6ae4382a4a788461566b3200bebd\",\n    \"code_uid\": \"File.0.50.74.1-rand6796931a\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cf6ae4382a4a788461566b3200bebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.File"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file1 = mr.File(label = 'Upload forward read', max_file_size = '10MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6acc6b57-67c9-493e-aad5-d9eceffdcc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file name: None\n",
      "Uploaded file path: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uploaded file name: {file1.filename}\")\n",
    "print(f\"Uploaded file path: {file1.filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01218b97-13e0-4430-bfea-810904af3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trimmed_fasta_with_ambiguities(output_title, base_calls, ambiguous_dict, \\\n",
    "                                            trim_start, trim_end, orient = 'F'):\n",
    "    \"\"\"\n",
    "    Generates a FASTA file with only the trimmed sequence and ambiguous base calls.\n",
    "\n",
    "    Args:\n",
    "        output_title (str): Title for the FASTA file.\n",
    "        base_calls (str): Original base calls as a string.\n",
    "        ambiguous_dict (dict): Dictionary mapping positions (0-based) to IUPAC codes.\n",
    "        trim_start (int): Start position for trimming (0-based).\n",
    "        trim_end (int): End position for trimming (0-based).\n",
    "    \n",
    "    Returns:\n",
    "        None. Outputs a trimmed FASTA file.\n",
    "    \"\"\"\n",
    "    # Convert the base_calls string into a list for easy modification\n",
    "    sequence_with_ambiguities = list(base_calls)\n",
    "\n",
    "    # Replace bases at ambiguous positions with the corresponding IUPAC code\n",
    "    for pos, iupac_code in ambiguous_dict.items():\n",
    "        if trim_start <= pos < trim_end:  # Only modify positions within the trimmed range\n",
    "            sequence_with_ambiguities[pos] = iupac_code\n",
    "\n",
    "    # Slice the sequence to include only the trimmed portion\n",
    "    trimmed_sequence_with_ambiguities = ''.join(sequence_with_ambiguities[trim_start:trim_end])\n",
    "    sequence = Seq(trimmed_sequence_with_ambiguities)\n",
    "\n",
    "    # Create a SeqRecord object for writing to FASTA\n",
    "    seq_record = SeqRecord(sequence, id=output_title, description=\"Trimmed sequence with ambiguous base calls\")\n",
    "\n",
    "    # Write the trimmed sequence to a FASTA file\n",
    "    # fasta_file = f\"{output_title}_trimmed.fasta\"\n",
    "    \n",
    "    # with open(fasta_file, \"w\") as output_handle:\n",
    "    \n",
    "        #if orient == 'R':\n",
    "            #SeqIO.write(seq_record.reverse_complement(), output_handle, \"fasta\")\n",
    "        \n",
    "        #else:\n",
    "            #SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "\n",
    "    # print(f\"Trimmed FASTA file '{fasta_file}' has been generated.\")\n",
    "    \n",
    "    return seq_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf50e0a4-ac13-4a59-be7d-67359dc05204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate ambiguous calls to IUPAC code\n",
    "def translate_to_iupac(ambiguous_bases):\n",
    "    # Sort the ambiguous bases to ensure they match the dictionary keys\n",
    "    sorted_bases = ''.join(sorted(ambiguous_bases))\n",
    "    return base_to_iupac.get(sorted_bases, 'N')  # Return 'N' if no match is found\n",
    "\n",
    "# Parameters\n",
    "quality_threshold = 40     # Quality score threshold for trimming\n",
    "min_consecutive_bases = 5  # Minimum number of consecutive high-quality bases needed to determine trim point\n",
    "\n",
    "# Function to find the first and last position to keep based on quality threshold\n",
    "def find_trim_position(phred_scores, direction='start'):\n",
    "    if direction == 'start':\n",
    "        for i in range(len(phred_scores) - min_consecutive_bases + 1):\n",
    "            if all(score >= quality_threshold for score in phred_scores[i:i + min_consecutive_bases]):\n",
    "                return i\n",
    "    elif direction == 'end':\n",
    "        for i in range(len(phred_scores) - min_consecutive_bases, -1, -1):\n",
    "            if all(score >= quality_threshold for score in phred_scores[i:i + min_consecutive_bases]):\n",
    "                return i + min_consecutive_bases\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0cb8cdd-e228-4c2c-bcff-888c29c7f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IUPAC nucleotide code dictionary\n",
    "iupac_codes = {\n",
    "    \"A\": \"A\",\n",
    "    \"C\": \"C\",\n",
    "    \"G\": \"G\",\n",
    "    \"T\": \"T\",\n",
    "    \"R\": \"AG\",    # A or G\n",
    "    \"Y\": \"CT\",    # C or T\n",
    "    \"S\": \"GC\",    # G or C\n",
    "    \"W\": \"AT\",    # A or T\n",
    "    \"K\": \"GT\",    # G or T\n",
    "    \"M\": \"AC\",    # A or C\n",
    "    \"B\": \"CGT\",   # C or G or T\n",
    "    \"D\": \"AGT\",   # A or G or T\n",
    "    \"H\": \"ACT\",   # A or C or T\n",
    "    \"V\": \"ACG\",   # A or C or G\n",
    "    \"N\": \"ACGT\"   # any base\n",
    "}\n",
    "\n",
    "# Reverse mapping from bases to IUPAC code\n",
    "base_to_iupac = {''.join(sorted(v)): k for k, v in iupac_codes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ee609e9-da42-4416-9725-ad0b29101f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq1_title = mr.Text(value='sequence', label='Name this sequence', rows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c869177-29d1-4232-bbbf-91ff8b928395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ambig_calls_and_plot(record, orient = 'F', output_title = 'sequence'):\n",
    "\n",
    "    # Extract peak locations, base calls, and quality scores\n",
    "    peak_locations = record.annotations['abif_raw']['PLOC2']\n",
    "    base_calls = record.annotations['abif_raw']['PBAS2'].decode('ascii')\n",
    "    phred_scores = record.letter_annotations[\"phred_quality\"]\n",
    "\n",
    "    # Find high-quality trimming positions\n",
    "    trim_start = find_trim_position(phred_scores, 'start')\n",
    "    trim_end = find_trim_position(phred_scores, 'end')\n",
    "    trimmed_len = trim_end - trim_start\n",
    "\n",
    "    # Define ambiguity threshold and the number of bases per plot\n",
    "    ambiguity_threshold = 3  # e.g., highest peak must be 3 times greater than the next highest\n",
    "    bases_per_plot = 50\n",
    "\n",
    "    # Extract trace data for G, A, T, C\n",
    "    channels = ['DATA9', 'DATA10', 'DATA11', 'DATA12']\n",
    "    trace_data = {base: record.annotations['abif_raw'][channel] for base, channel in zip(\"GATC\", channels)}\n",
    "\n",
    "    # Find global max intensity and max Phred score for consistent plotting\n",
    "    max_intensity = max(max(trace_data[base]) for base in \"GATC\")\n",
    "    max_phred_score = max(phred_scores)\n",
    "\n",
    "    # Set consistent y-limits\n",
    "    intensity_ylim = (-0.4, max_intensity * 1.1)  # a little above max to give space\n",
    "    phred_ylim = (0, max_phred_score + 5)  # add a small buffer above max Phred\n",
    "\n",
    "    # Initialize lists for ambiguous positions, original base calls, and alternatives\n",
    "    ambiguous_positions = []\n",
    "    original_base_calls = []\n",
    "    alternative_base_calls = []\n",
    "    alternative_intensities = []\n",
    "\n",
    "    # Loop through all positions in the sequence to check for ambiguity\n",
    "    for i, position in enumerate(peak_locations):\n",
    "        intensities = {base: trace_data[base][position] for base in \"GATC\"}\n",
    "        sorted_bases = sorted(intensities, key=intensities.get, reverse=True)\n",
    "\n",
    "        if base_calls[i] == \"N\": # skip the ambiguity check if the original base call was already ambiguous\n",
    "            original_base_calls.append(base_calls[i])\n",
    "            continue\n",
    "\n",
    "        # Check for ambiguous base calls based on the threshold\n",
    "        if intensities[sorted_bases[0]] < ambiguity_threshold * intensities[sorted_bases[1]]:\n",
    "            ambiguous_positions.append(i)\n",
    "            original_base_calls.append(base_calls[i])\n",
    "            alternatives = [(base, intensities[base]) for base in sorted_bases if intensities[base] >= intensities[sorted_bases[0]] / ambiguity_threshold]\n",
    "            alternative_base_calls.append([base for base, _ in alternatives])\n",
    "            alternative_intensities.append([intensity for _, intensity in alternatives])\n",
    "\n",
    "    # Make a dictionary with the position of the ambiguous calls and the corresponding IUPAC code\n",
    "    ambiguous_dict = {}\n",
    "    for position, alternatives in zip(ambiguous_positions, alternative_base_calls):\n",
    "        ambiguous_dict[position] = translate_to_iupac(alternatives)\n",
    "\n",
    "    # Loop through the sequence in chunks of `bases_per_plot` and plot each chunk\n",
    "    # num_chunks = len(base_calls) // bases_per_plot + (1 if len(base_calls) % bases_per_plot else 0)\n",
    "\n",
    "    # Output the start and end positions for trimming (adjusted for display purposes)\n",
    "    print(\"Trim Start Position:\", trim_start + 1)  # Adjust display only (shifted by 1)\n",
    "    print(\"Trim End Position:\", trim_end)  # No need to adjust since this is end-exclusive\n",
    "\n",
    "    # Set initial values for start and end based on the number of bases per plot\n",
    "    # Set initial values for start and end based on the number of bases per plot\n",
    "    start = 0\n",
    "    end = min(len(base_calls), bases_per_plot)  # Show first 50 bases initially\n",
    "    \n",
    "    # Plot the trace data for the initial chunk\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 3))\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    colors = {'A': 'green', 'C': 'blue', 'G': 'black', 'T': 'red'}\n",
    "    slider_color = 'White'\n",
    "    \n",
    "    # Create a secondary y-axis for Phred scores\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # App slider widget\n",
    "    pos_to_plot = mr.Slider(value=0, min=0, max=len(base_calls), label=\"Region to view\", \n",
    "                        step=1, url_key=\"slider\")\n",
    "    \n",
    "    # Function to plot the current chunk of data\n",
    "    def plot_chunk(start, end):\n",
    "        ax1.clear()  # Clear previous data\n",
    "        ax2.clear()  # Clear Phred score data\n",
    "\n",
    "        for i, position in enumerate(peak_locations[start:end]):\n",
    "            for base in \"GACT\":\n",
    "                ax1.plot(start + i + 1, trace_data[base][position], 'o', color=colors[base], label=base if i == 0 else \"\")\n",
    "        \n",
    "        # Annotate original base calls below the x-axis\n",
    "        for i, (pos, base_call) in enumerate(zip(range(start + 1, end + 1), base_calls[start:end])):\n",
    "            ax1.text(pos, -0.15, base_call, ha='center', va='top', transform=ax1.get_xaxis_transform(), fontsize=10)\n",
    "        \n",
    "        # Annotate ambiguous calls\n",
    "        for pos in range(start, end):\n",
    "            if pos in ambiguous_dict:\n",
    "                ax1.text(pos + 1, -0.25, ambiguous_dict[pos], ha='center', va='top', transform=ax1.get_xaxis_transform(), fontsize=9, \\\n",
    "                         color='black', backgroundcolor = 'yellow', fontweight = 'bold')\n",
    "\n",
    "    \n",
    "        # Set plot limits and labels\n",
    "        ax1.set_xlim(start + 1, end)\n",
    "        ax1.set_ylim(intensity_ylim)\n",
    "        #ax1.set_xlabel('Base Number')\n",
    "        ax1.set_ylabel('Signal Intensity')\n",
    "        ax1.set_title(f'Sanger Sequencing Chromatogram (Bases {start + 1} to {end})')\n",
    "    \n",
    "        # Update the Phred score axis\n",
    "        ax2.plot(range(start + 1, end + 1), phred_scores[start:end], 's-', color='purple', label='Phred Quality Score', alpha=0.7)\n",
    "        ax2.set_ylabel('Phred Quality Score')\n",
    "        ax2.yaxis.set_label_position(\"right\")\n",
    "        ax2.yaxis.tick_right()\n",
    "        ax2.set_ylim(phred_ylim)\n",
    "        ax2.legend(loc=\"upper right\")\n",
    "        ax1.legend(loc=\"upper left\")\n",
    "        plt.draw()\n",
    "\n",
    "    # Initial plot of the first chunk\n",
    "    plot_chunk(pos_to_plot.value, pos_to_plot.value + 75)\n",
    "    \n",
    "    # Slider params\n",
    "    #axis_position = plt.axes([0.2, 0.1, 0.65, 0.03], facecolor=slider_color)\n",
    "    #slider_position = Slider(axis_position, 'Pos', 0, max(0, len(base_calls) - bases_per_plot))\n",
    "    \n",
    "    # Update function for the slider\n",
    "    #def update(val):\n",
    "        #pos = int(slider_position.val)\n",
    "        #start = pos\n",
    "        #end = min(start + bases_per_plot, len(base_calls))\n",
    "        #plot_chunk(start, end)\n",
    "    \n",
    "    # Connect the slider to the update function\n",
    "    #slider_position.on_changed(update)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Convert the base_calls string into a list for easy modification\n",
    "    sequence_with_ambiguities = list(base_calls)\n",
    "\n",
    "    # Replace bases at ambiguous positions with the corresponding IUPAC code\n",
    "    for pos, iupac_code in ambiguous_dict.items():\n",
    "        sequence_with_ambiguities[pos] = iupac_code\n",
    "\n",
    "    # Slice the sequence to include only the trimmed portion\n",
    "    trimmed_sequence_with_ambiguities = ''.join(sequence_with_ambiguities[trim_start:trim_end])\n",
    "    sequence = Seq(trimmed_sequence_with_ambiguities)\n",
    "\n",
    "    # Create a SeqRecord object for writing to FASTA\n",
    "    seq_record = SeqRecord(sequence, id=output_title, description=\"Trimmed sequence with ambiguous base calls\")\n",
    "\n",
    "    # Write the trimmed sequence to a FASTA file\n",
    "    # fasta_file = f\"{output_title}_trimmed.fasta\"\n",
    "    \n",
    "    # with open(fasta_file, \"w\") as output_handle:\n",
    "    \n",
    "        #if orient == 'R':\n",
    "            #SeqIO.write(seq_record.reverse_complement(), output_handle, \"fasta\")\n",
    "        \n",
    "        #else:\n",
    "            #SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "\n",
    "    # print(f\"Trimmed FASTA file '{fasta_file}' has been generated.\")\n",
    "\n",
    "    # Assuming `base_calls` is the original base calls string, `ambiguous_dict` contains ambiguous positions,\n",
    "    # and `trim_start` and `trim_end` are the start and end positions for trimming.\n",
    "    \n",
    "    # seq_record = generate_trimmed_fasta_with_ambiguities(output_title, base_calls, ambiguous_dict, trim_start, trim_end, orient=orient)\n",
    "    # Include the Phred scores with the seq record\n",
    "    seq_record.letter_annotations[\"phred_score\"] = phred_scores[trim_start:trim_end]\n",
    "    # Add the intensity at each peak in each channel to the sequence record\n",
    "    for char in 'GATC':\n",
    "        intensity = []\n",
    "        for peak in peak_locations:\n",
    "            intensity.append(trace_data[char][peak])\n",
    "        seq_record.letter_annotations[char] = intensity[trim_start:trim_end]\n",
    "\n",
    "    # Handle reverse complement if needed\n",
    "    if orient == 'R':\n",
    "        #phred_scores.reverse()\n",
    "        return seq_record.reverse_complement()\n",
    "    else:\n",
    "        return seq_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aecbc0ac-39a2-440c-87d7-270a39992bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate1 = mr.Button(label = \"Generate fwd plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0b03fd-e1b5-40a6-9659-adbe6699fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if generate1.clicked:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f5e8027-c489-415b-89f0-7c798ab28218",
   "metadata": {},
   "outputs": [],
   "source": [
    "record1 = None\n",
    "seq1 = None\n",
    "seq2 = None\n",
    "if file1.filepath is not None:\n",
    "    with open(file1.filepath, \"rb\") as infile:\n",
    "        record1 = SeqIO.read(infile, \"abi\")\n",
    "    seq1 = make_ambig_calls_and_plot(record1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01cd42-68f2-43b3-9618-c9597d4c5e93",
   "metadata": {},
   "source": [
    "## Reverse read plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7440e0a0-dd61-4d38-ba06-15a954ab8910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"File\",\n    \"max_file_size\": \"10MB\",\n    \"label\": \"Upload reverse read\",\n    \"model_id\": \"818feedcac8942d98dffc6decca9b837\",\n    \"code_uid\": \"File.0.50.74.1-randfb54c320\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818feedcac8942d98dffc6decca9b837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.File"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file2 = mr.File(label = 'Upload reverse read', max_file_size = '10MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d68157ce-27da-427c-9010-33972da18c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file name: None\n",
      "Uploaded file path: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uploaded file name: {file2.filename}\")\n",
    "print(f\"Uploaded file path: {file2.filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8515dc73-176f-4fae-93a4-1c262b069aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate2 = mr.Button(label = \"Generate fwd plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c594fd9-876e-4996-820f-edc79eba9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq2_title = mr.Text(value='sequence', label='Name this sequence', rows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1af6fdaa-35f2-49e2-9c0d-d24fe82a2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if generate2.clicked:\n",
    "record2 = None\n",
    "if file2.filepath is not None:\n",
    "    with open(file2.filepath, \"rb\") as infile:\n",
    "        record2 = SeqIO.read(infile, \"abi\")\n",
    "\n",
    "    seq2 = make_ambig_calls_and_plot(record2, orient = 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ee340cb-65cf-4a63-9d2e-3ff8a03199ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "\n",
    "# Perform local alignment using Smith-Waterman\n",
    "def align_sequences(seq1, seq2):\n",
    "    # Perform local alignment using Smith-Waterman (localms)\n",
    "    alignments = pairwise2.align.localms(seq1, seq2, 2, -1, -5, -2, one_alignment_only=True)\n",
    "    \n",
    "    # Return the best alignment\n",
    "    return alignments[0]\n",
    "\n",
    "# Function to generate consensus sequence based on Phred scores\n",
    "def generate_consensus_with_phred(aligned_seq1, aligned_seq2, phred_scores1, phred_scores2):\n",
    "    consensus = []\n",
    "    source_base = [] # 1 is seq1, 2 is seq2, 3 is they called same base, 4 is they called different base but equal phred score\n",
    "\n",
    "    gaps1 = len(aligned_seq1) - len(aligned_seq1.rstrip('-')) # count the number of gaps in aligned_seq1\n",
    "    gaps2 = len(aligned_seq2) - len(aligned_seq2.lstrip('-')) # count the number of gaps in aligned_seq2\n",
    "    # Iterate through the aligned sequences and compare each base\n",
    "    for i, (base1, base2) in enumerate(zip(aligned_seq1, aligned_seq2)):\n",
    "        # Handle gaps\n",
    "        if base1 == '-':\n",
    "            consensus.append(base2)\n",
    "            source_base.append(2)\n",
    "        elif base2 == '-':\n",
    "            consensus.append(base1)\n",
    "            source_base.append(1)\n",
    "        elif base1 == base2:\n",
    "            consensus.append(base1) # If bases are the same, use either one\n",
    "            source_base.append(3)\n",
    "        else:\n",
    "            # Compare Phred scores to choose the base with the higher score\n",
    "            print(f'Consensus position: {i + 1}')\n",
    "            print(f'Base call from fwd read: {base1} with Phred score {phred_scores1[i]}')\n",
    "            print(f'Base call from rev read: {base2} with Phred score {phred_scores2[i]}')\n",
    "            if phred_scores1[i] > phred_scores2[i]:\n",
    "                consensus.append(base1)\n",
    "                source_base.append(1)\n",
    "                print('Resolved to use call from fwd read.')\n",
    "            elif phred_scores2[i] > phred_scores1[i]:\n",
    "                consensus.append(base2)\n",
    "                source_base.append(2)\n",
    "                print('Resolved to use call from rev read.')\n",
    "            # this would be unlikely, but would handle situations where phred scores are equal\n",
    "            elif phred_scores1[i] == phred_scores2[i]:\n",
    "                \n",
    "                # first will need to convert any IUPAC codes *back* to bases:\n",
    "                possible_calls = set()\n",
    "                if base1 not in ['A', 'C', 'G', 'T']:\n",
    "                    base1_set = set(iupac_codes[base1])\n",
    "                    possible_calls.update(base1_set)\n",
    "                    \n",
    "                else: possible_calls.add(base1)\n",
    "                        \n",
    "                if base2 not in ['A', 'C', 'G', 'T']:\n",
    "                    base2_set = set(iupac_codes[base2])\n",
    "                    possible_calls.update(base2_set)\n",
    "                    \n",
    "                else: possible_calls.add(base2)\n",
    "                \n",
    "                sorted_possible_calls = ''.join(sorted(list(possible_calls)))\n",
    "                call = base_to_iupac.get(sorted_possible_calls, 'N')\n",
    "                consensus.append(call)  # Return 'N' if no match is found\n",
    "                print('Phred scores from fwd and reverse reads are equal.')\n",
    "                print(f'Ambiguous nucleotide: {call}')\n",
    "                source_base.append(4)\n",
    "                \n",
    "    return ''.join(consensus), source_base\n",
    "\n",
    "# Main function to align sequences and generate the consensus\n",
    "def align_and_generate_consensus(seq1, seq2):\n",
    "    # Align sequences\n",
    "    best_alignment = align_sequences(seq1.seq, seq2.seq)\n",
    "    \n",
    "    phred_scores1 = seq1.letter_annotations[\"phred_score\"]\n",
    "    phred_scores2 = seq2.letter_annotations[\"phred_score\"]\n",
    "    \n",
    "    # Extract the aligned sequences\n",
    "    aligned_seq1, aligned_seq2, score, start, end = best_alignment\n",
    "    \n",
    "    # Generate consensus sequence based on Phred scores\n",
    "    consensus_sequence, source_base = generate_consensus_with_phred(aligned_seq1, aligned_seq2, phred_scores1, phred_scores2)\n",
    "\n",
    "    # Print the alignment and the consensus sequence\n",
    "    print(\"Alignment:\")\n",
    "    print(pairwise2.format_alignment(*best_alignment))\n",
    "\n",
    "    # Print the alignment and the consensus sequence\n",
    "    print(f\"Consensus sequence generated with length of {str(len(consensus_sequence))} bases.\")\n",
    "    \n",
    "    return consensus_sequence, source_base, aligned_seq1, aligned_seq2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2340b-36fe-4fe5-b1d9-3331532d877f",
   "metadata": {},
   "source": [
    "## Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69eaa4df-aabc-4ae7-a3e9-012f065aee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {1: 'purple', 2: 'orange', 3: 'green', 4: 'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a46e08-d128-410b-84af-d5ec1392a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig_base_codes = ['R', 'Y', 'S', 'W', 'K', 'M', 'B', 'D', 'H', 'V', 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5145469b-0a11-4202-ba5e-e37ffb2a9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_consensus(record):\n",
    "\n",
    "    # Plot the trace data for the initial chunk\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 3))\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    colors = {'A': 'green', 'C': 'blue', 'G': 'black', 'T': 'red'}\n",
    "    #border = {'1': 'purple', '2': 'orange'}\n",
    "    shape = {'1': 'o', '2': 's'} \n",
    "    \n",
    "    # Create a secondary y-axis for Phred scores\n",
    "    #ax2 = ax1.twinx()\n",
    "    \n",
    "    # App slider widget\n",
    "    cons_pos_to_plot = mr.Slider(value=0, min=0, max=len(record.seq), label=\"Consensus\", \n",
    "                        step=1, url_key=\"slider\")\n",
    "\n",
    "    intensity_channels = ['G1', 'G2', 'A1', 'A2', 'T1', 'T2', 'C1', 'C2']\n",
    "    # Find global max intensity and max Phred score for consistent plotting\n",
    "    max_intensity = max(max([i for i in consensus_record.letter_annotations[val] if i != '-']) for val in intensity_channels)\n",
    "    #max_phred_score = max(phred_scores)\n",
    "\n",
    "    # Set consistent y-limits\n",
    "    intensity_ylim = (-0.4, max_intensity * 1.1)  # a little above max to give space\n",
    "    #phred_ylim = (0, max_phred_score + 5)  # add a small buffer above max Phred\n",
    "    \n",
    "    # Function to plot the current chunk of data\n",
    "    def plot_chunk(start, end):\n",
    "        ax1.clear()  # Clear previous data\n",
    "        #ax2.clear()  # Clear Phred score data\n",
    "\n",
    "        for val in intensity_channels:\n",
    "            for i, signal in enumerate(consensus_record.letter_annotations[val][start:end]):\n",
    "                if signal != '-':\n",
    "                    base = val[0]\n",
    "                    s = val[1]\n",
    "                    ax1.plot(start + i + 1, signal, shape[s], color=colors[base], label=f'{base}{s}' if i == 0 else \"\")\n",
    "        \n",
    "        # Annotate consensus sequence below the x-axis\n",
    "        for i, (pos, base_call) in enumerate(zip(range(start + 1, end + 1), str(consensus_record.seq)[start:end])):\n",
    "            if base_call != '-':\n",
    "                if base_call in ambig_base_codes: \n",
    "                    ax1.text(pos, -0.15, base_call, ha='center', va='top', transform=ax1.get_xaxis_transform(), fontsize=10, \\\n",
    "                         color=color_dict[consensus_record[start:end].letter_annotations['source_base'][i]], backgroundcolor = 'yellow', fontweight = 'bold')\n",
    "                else:\n",
    "                    ax1.text(pos, -0.15, base_call, ha='center', va='top', transform=ax1.get_xaxis_transform(), fontsize=10, \\\n",
    "                         color=color_dict[consensus_record[start:end].letter_annotations['source_base'][i]], fontweight = 'bold')\n",
    "            \n",
    "    \n",
    "        # Set plot limits and labels\n",
    "        ax1.set_xlim(start + 1, end)\n",
    "        ax1.set_ylim(intensity_ylim)\n",
    "        #ax1.set_xlabel('Base Number')\n",
    "        ax1.set_ylabel('Signal Intensity')\n",
    "        ax1.set_title(f'Sanger Sequencing Chromatogram (Bases {start + 1} to {end})')\n",
    "    \n",
    "        # Update the Phred score axis\n",
    "        #ax2.plot(range(start + 1, end + 1), phred_scores[start:end], 's-', color='purple', label='Phred Quality Score', alpha=0.7)\n",
    "        #ax2.set_ylabel('Phred Quality Score')\n",
    "        #ax2.yaxis.set_label_position(\"right\")\n",
    "        #ax2.yaxis.tick_right()\n",
    "        #ax2.set_ylim(phred_ylim)\n",
    "        #ax2.legend(loc=\"upper right\")\n",
    "        ax1.legend(loc=\"upper left\")\n",
    "        plt.draw()\n",
    "    \n",
    "    # Initial plot of the first chunk\n",
    "    plot_chunk(cons_pos_to_plot.value, cons_pos_to_plot.value + 75)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74ab0c4e-9634-4284-bc26-8244d1d4e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_consensus(seq1, seq2):\n",
    "    consensus, source_base, aligned_seq1, aligned_seq2 = align_and_generate_consensus(seq1, seq2)\n",
    "    pos_to_split = np.where(np.array(source_base)[:-1] != np.array(source_base)[1:])[0] # find out where the source base changes\n",
    "    pos_to_split = pos_to_split + 1 # adjust so list shows end position\n",
    "    pos_to_split = pos_to_split.tolist() # convert to list\n",
    "    pos_to_split.insert(0, 0) # add zero to beginning of list\n",
    "    pos_to_split.append(len(consensus)) # add end of sequence\n",
    "\n",
    "    gaps1 = len(aligned_seq1) - len(aligned_seq1.rstrip('-')) # count the number of gaps in aligned_seq1\n",
    "    gaps2 = len(aligned_seq2) - len(aligned_seq2.lstrip('-')) # count the number of gaps in aligned_seq2\n",
    "    to_print = str()\n",
    "    #print(pos_to_split)\n",
    "\n",
    "    for i, pos in enumerate(pos_to_split):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        start = pos_to_split[i-1]\n",
    "        end = pos_to_split[i]\n",
    "        new_section = consensus[start:end]\n",
    "    \n",
    "        col = color_dict[source_base[start]]\n",
    "        to_print += colorize(new_section, color = col)\n",
    "\n",
    "    print(consensus)\n",
    "\n",
    "    print('')\n",
    "\n",
    "    print('Scroll the sequence below to see the alignment region and which read the base calls came from.')\n",
    "\n",
    "    display(Markdown(colorize('Forward read', 'purple')))\n",
    "    display(Markdown(colorize('Reverse read', 'orange')))\n",
    "    display(Markdown(colorize('Alignment (reads agree)', 'green')))\n",
    "\n",
    "    # Highlight ambiguous/noncanonical bases\n",
    "\n",
    "    pre = \"<span style='background-color: yellow'>\"\n",
    "    post = \"</span>\"\n",
    "    for ambig in ambig_base_codes:\n",
    "        to_print = to_print.replace(ambig, pre + ambig + post)\n",
    "        \n",
    "    #display(Markdown(to_print))\n",
    "\n",
    "    # Create a new seq record based on the consensus\n",
    "    consensus_record = SeqRecord(Seq(consensus))\n",
    "\n",
    "\n",
    "\n",
    "    new_seq1 = SeqRecord(Seq(seq1.seq + '-' * gaps1))\n",
    "    for annot in seq1.letter_annotations.keys(): # add gaps to all the corresponding annotations, too\n",
    "        new_seq1.letter_annotations[annot] = seq1.letter_annotations[annot] + list('-' * gaps1)\n",
    "\n",
    "    new_seq2 = SeqRecord(Seq('-' * gaps2 + seq2.seq))\n",
    "    for annot in seq2.letter_annotations.keys(): # add gaps to all the corresponding annotations, too\n",
    "        new_seq2.letter_annotations[annot] = list('-' * gaps2) + seq2.letter_annotations[annot]\n",
    "\n",
    "    # For the new record, record both the annotations from Seq1 and from Seq2\n",
    "    consensus_record.letter_annotations['source_base'] = source_base\n",
    "    consensus_record.letter_annotations['phred_seq1'] = new_seq1.letter_annotations['phred_score']\n",
    "    consensus_record.letter_annotations['phred_seq2'] = new_seq2.letter_annotations['phred_score']\n",
    "    # Since we have taken the reverse complement of the second sequence, the C/G and A/T must be swapped in the signal intensities\n",
    "    consensus_record.letter_annotations['G1'] = new_seq1.letter_annotations['G']\n",
    "    consensus_record.letter_annotations['C2'] = new_seq2.letter_annotations['G']\n",
    "    consensus_record.letter_annotations['A1'] = new_seq1.letter_annotations['A']\n",
    "    consensus_record.letter_annotations['T2'] = new_seq2.letter_annotations['A']\n",
    "    consensus_record.letter_annotations['T1'] = new_seq1.letter_annotations['T']\n",
    "    consensus_record.letter_annotations['A2'] = new_seq2.letter_annotations['T']\n",
    "    consensus_record.letter_annotations['C1'] = new_seq1.letter_annotations['C']\n",
    "    consensus_record.letter_annotations['G2'] = new_seq2.letter_annotations['C']\n",
    "\n",
    "    return(consensus_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5940e3e6-413c-4bff-a57b-367dd24656c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (seq1 is not None) and (seq2 is not None): \n",
    "    consensus_record = find_consensus(seq1, seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a59887e6-a1d9-4034-ad70-a10f4a4649ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate3 = mr.Button(label = \"Find overlap consensus\")\n",
    "#generate3 = True (FOR TESTING WITHOUT BUTTON)\n",
    "\n",
    "#if generate3.clicked:\n",
    "#if generate3: (FOR TESTING WITHOUT BUTTON)\n",
    "    #consensus_record = find_consensus(seq1, seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b58fa69-1fff-4967-aae1-712fe6ed771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try: plot_consensus(consensus_record)\n",
    "except NameError:\n",
    "   print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b675871-7dfe-4978-8a60-9c1b23678d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"OutputDir\",\n    \"model_id\": \"output-dir\",\n    \"code_uid\": \"OutputDir.0.50.18.1-rand56945934\"\n}",
      "text/html": [
       "<h3>Output Directory</h3><small>This output won't appear in the web app.</small>"
      ],
      "text/plain": [
       "mercury.OutputDir"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = mr.OutputDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "565a7d5a-00d3-4fa2-9763-7f40c874cfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf2ddbe-8bef-47f5-bf54-454efbf4cdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory path: .\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output directory path: {output_dir.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff856da4-f67d-4c09-89eb-1e19deaeb292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Text\",\n    \"value\": \"sequence\",\n    \"sanitize\": true,\n    \"rows\": 1,\n    \"label\": \"Name the merged sequence for export\",\n    \"model_id\": \"b04097a7e0c74de9b8be44688099ab9f\",\n    \"code_uid\": \"Text.0.50.78.1-rand1d677f94\",\n    \"url_key\": \"\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04097a7e0c74de9b8be44688099ab9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Text\",\n    \"value\": \"description\",\n    \"sanitize\": true,\n    \"rows\": 1,\n    \"label\": \"Give a description of the file\",\n    \"model_id\": \"fafb778fb8214256ac008e90fd812712\",\n    \"code_uid\": \"Text.0.50.78.2-rand1e40acf3\",\n    \"url_key\": \"\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafb778fb8214256ac008e90fd812712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_title = mr.Text(value='sequence', label='Name the merged sequence for export', rows = 1)\n",
    "merge_desc = mr.Text(value='description', label='Give a description of the file', rows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe27e649-4ee8-4101-ad71-012451bf6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = merge_title.value + '.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "958afe40-02b9-42d7-a170-55d057b06eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sequence.fa'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccae8632-08b1-4bdf-be3e-cf21c002aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_name = os.path.join(output_dir.path, outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42ed3fe0-52e5-415a-a132-b63a9ad900a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": "{\n    \"widget\": \"Button\",\n    \"label\": \"Write to FASTA\",\n    \"style\": \"primary\",\n    \"value\": false,\n    \"model_id\": \"ced144203f694e5e8f1a3aa619641aea\",\n    \"code_uid\": \"Button.0.50.58.1-rand618184bb\",\n    \"disabled\": false,\n    \"hidden\": false\n}",
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced144203f694e5e8f1a3aa619641aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mercury.Button"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate4 = mr.Button(label = \"Write to FASTA\")\n",
    "\n",
    "if generate4.clicked:\n",
    "    with open(outfile_name, \"w\") as outfile:\n",
    "        SeqIO.write(SeqRecord(Seq(consensus_record.seq), id=merge_title.value, description=merge_desc.value), outfile, 'fasta')\n",
    "\n",
    "    print(\"Fasta successfully generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d90017-ee5c-4c66-9cfe-c225dc98e372",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
